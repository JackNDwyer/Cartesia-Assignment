# Appendix: Initial Notes: Detailed Feedback

Being that I am familiar with Cartesia, I will be assuming the persona of a developer with a medium level of familiarity with Voice Agents. I am seeking an end-to-end solution to create voice agents to handle support calls for a health tech startup in El Paso, Texas, that manages appointment scheduling for English and Spanish speakers. I have a few workflows I hope to build, each needing decision trees and tool calling. I have experimented with LiveKit, Vapi, and ElevenLabs, and have also tried OpenAI's voice stack (TTS, STT, Pipeline vs Speech-to-speech, Realtime).

I saw the Sonic 3 release on X and noticed Cartesia also has a voice agents product, so I am visiting the website for the first time to learn about Sonic 3 and their voice agents product.

Website/Dashboard First Impressions (90 min including typing)

## Website Homepage

![Cartesia Homepage](/Public/hero-top-landing.png)

At first glance, I'm seeing that Cartesia is primarily a text-to-speech inference provider. The homepage directs me to /sonic. The entire upper half of the homepage is centered around the new Sonic TTS model: it's fast, natural, and expressive, with voices for a variety of use cases.

<span style="font-size: 0.95em; color: #888;"><em>Idea: As the Line and Ink products mature, create a new homepage that touches on all of these models (assuming strategically Cartesia wants to push those).</em></span>

![Agents Powering Sonic Page](/Public/agents-powering-sonic-page.png)

As I scroll to the "Powering Agents" section, I initially think it’s about building voice agents, but instead, it continues discussing how Cartesia's TTS is powering voice agents.

I do appreciate that multi-lingual support is mentioned, with different dialects of Spanish being listed.

I see there is a TTS API, as well as an SDK. I also notice SOC 2, HIPAA, and PCI compliance.

There is no mention of agents (or STT for that matter) on the homepage.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Mention Line Agents and Ink STT with links so users can cmd-click to open those pages in the background.</em></span>

## Website Agents Page
With a grasp of the TTS product, I see “Agents” in the header.

![Line Hero](/Public/hero-line.png)

I'm now looking at what I hope to integrate. I see the text: "Line is a code-first ecosystem to get from zero—to your first agent—to your best agent, in record time."

It's unclear what "Line" is: both the word and its usage, as well as "code-first ecosystem." Since I clicked Agents, I'm assuming Line is an agent builder.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Rework this slightly to something like "Line is a code-first agent builder to rapidly prototype and deploy production-ready voice agents for any use case."</em></span>

![Line Start Anywhere](/Public/line-start-anywhere.png)

This section inspires confidence that you offer what I need. My company already uses two LLMs (OpenAI and Gemini) that seem compatible, and it looks like you have templates to help get started, plus a text-to-agent feature.

![Agents Features](/Public/agents-features.png)

I do not see any mention of tool calling (other than a hidden RAG-focused Tool Calling bullet in the "Build" section). I also see no mention of building workflows, decision trees, or handoffs. It would also be nice to talk to a realtime agent to gauge quality/latency in production. Other websites let me do that instead of just showing snippets.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Communicate tool calling and handoffs/workflows more clearly.</em></span>
<span style="font-size: 0.95em; color: #888;"><em>Idea: Add a realtime demo.</em></span>

As I continue scrolling, there are a few industries listed, including Healthcare. I click on it.

![Healthcare Page](/Public/healthcare-page.png)

This page inspires confidence through social proof and real-world examples. I would still like to try one of the voice agents—via widget or phone number—but it builds trust.

I click "Give it a try" and am taken to a Sign Up page. Before signing up, I want to view pricing and docs. There is no navigation on the sign up page, but before hitting back, I notice a small "?" and on click, it’s actually a menu. I click `Pricing` first.

![Sign Up Page](/Public/sign-up-page.png)

<span style="font-size: 0.95em; color: #888;"><em>Idea: Make the menu button more clear or add simple navigation to docs/pricing. The ? suggests support, but not necessarily docs/pricing.</em></span>

## Website Pricing Page
![Pricing Main](/Public/pricing-main.png)

This page generally makes sense. It's busy, but as I focus on what I need, it makes sense.

I see a lot of numbers: monthly fees, credits, and agent credits. I don’t think I need cloning, but my organization expects up to 5 calls at once across 4 different agents.

The startup plan seems okay for my use case: 5 concurrent on TTS, 5 agent slots with 20 concurrency.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Startup Plan = 20 Agents concurrency != 5 TTS concurrency. I understand the AI isn't always talking, but these numbers should be closer.</em></span>

Pricing is somewhat difficult to calculate. There is duration-based pricing for Line Agents and STT, but usage-based pricing for the TTS model.

I then return to the Sign Up page, which strongly emphasizes Sonic 3.

<span style="font-size: 0.95em; color: #888;"><em>Idea: A testimonial or more use cases/functionality could be useful here. Right now it's just another announcement about Sonic 3.</em></span>

## Docs
The Docs are very strong. Going through sequentially via the bottom nav was nice.

Generating a snippet via cURL/Python/JS makes sense, though since I'm looking to create a voice agent, doing a `Bytes` call, which seems more suited for batch calls, isn’t super relevant.

I got it working very easily and the token-based auth is clear. I encountered what I believe is a bug where generated Mp3 files playback at different speeds based on Sample Rate.

```
curl -N -X POST "https://api.cartesia.ai/tts/bytes" \
        -H "Cartesia-Version: 2025-04-16" \
        -H "X-API-Key: $CARTESIA_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
            "transcript": "Howdy!",
            "model_id": "sonic-3",
            "voice":
                {
                    "mode":"id",
                    "id": "694f9389-aac1-45b6-b726-9d9369183238"
                },
            "output_format":
                {
                    "container":"mp3",
                    "bit_rate":64000,
                    "sample_rate":44100 // 16000 causes fast, high pitch playback
                }
            }' > howdy_sample.mp3
```

I'm not yet sold on using Cartesia's Agents product, but I do like the TTS product and, regardless of which agents platform I use, I'll likely use Sonic TTS. I want to find a WebSocket endpoint. I eventually locate it in the API reference.

![Docs Formats](/Public/docs-formats.png)

<span style="font-size: 0.95em; color: #888;"><em>Idea: Link to the different TTS endpoints in the info box shown in the screenshot.</em></span>

## Playground Text to Speech

**Note: I know your product very well so I'll continue writing from the persona of the dev.**

![TTS Panel with Banner](/Public/tts-panel-with-banner.png)

After signing up, the first thing I see is a `Text to Speech` page. I notice the banner on top announcing Sonic-3 is live. On my Macbook Air, this takes up a significant amount of screen real estate.

<span style="font-size: 0.95em; color: #888;"><em>Idea: The banner can be shrunk to one line of text. It currently spans more than two.</em></span>

I see a strong emphasis on Voice Tools (it's the top section) on the sidebar.

There are a few example prompts to get started with. Some appear to be real-time agents—"Schedule an appointment" or "Concierge." When I click them, they fill the Text-to-Speech box with a sentence.

This is useful, as I'm learning to use the tool and trying different examples, but when I click one example prompt, they all disappear. If I hit speak, the text remains. When I realized I needed to erase the text to get prompts back, they're different examples.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Have an example prompt library that can easily be scrolled through—or pick a set of standard example prompts. Allow selecting other example prompts without needing to delete the filled text.</em></span>

![Emote Sonic 2](/Public/emote-sonic-2.png)

Looking at the "Controls", I see multiple models. It defaults to Sonic 3. I was compelled to try different models, and when swapping models from Sonic 3 to Sonic 2 *after* clicking an example prompt, the emotion and emote tags remain—which is odd, since they don't work with Sonic 2. The model spoke the emote "Laughter" for Sonic 2.

[![Example Prompts Video](https://img.youtube.com/vi/QavVoKRJLFw/0.jpg)](https://www.youtube.com/watch?v=QavVoKRJLFw)

<span style="font-size: 0.95em; color: #888;"><em>Idea: When I change models, remove the emotion tags, or at least have the TTS model ignore them if incompatible and provide a warning: "model not compatible with emotion tags."</em></span>

Otherwise, controls make sense. Speed and Volume are intuitive. Transcription Language I assume lets me generate specific language snippets, even if that mismatches the voice language.

![Emoji](/Public/emoji.png)

When I use Sonic 3, emotions (reflected by different emojis) don't show in the text box, but they highlight on the sidebar, which I assume means they’re working.

<span style="font-size: 0.95em; color: #888;"><em>Idea: The emoji buttons on the `Text to Speech` page should add the text tag in the text box. Right now users can add a text tag or use the emoji. If Cartesia wants to train users on text tags, tags should always be shown in the text box.</em></span>

I clicked "Voice", which looks like a dropdown, but then a modal appears.

It starts on `All`, and then when I click "Cartesia Voices" nothing changes.

![All Voices](/Public/all-voices.png)
![Cartesia Voices](/Public/cartesia-voices.png)

When I clone a voice and use it, the `RECENTLY USED` section in the `All` panel and the `Cartesia` panel remain identical. I'd expect `All` to include the new cloned voice I just used. If I scroll down in `All`, I do eventually get to my cloned voice, but I don’t understand the default sort order.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Order the `All` voices so it’s understandable for users, and ensure the `RECENTLY USED` section in `All` reflects recently used cloned voices. On refresh, it didn't update.</em></span>

![My Voices TTS](/Public/my-voices-tts.png)

The "My Voices" panel is empty.

![My Voices Voices](/Public/my-voices-voices.png)

<span style="font-size: 0.95em; color: #888;"><em>Idea: Add a link to the cloning page in the empty state so users can create their own voice if they want. Same situation for "Starred." Instead of an empty state, give a CTA to `Star` favorite voices for easy access. This already exists for the empty state of `My Voices` on the `Voices` page.</em></span>

I like that on the Voices page, I can play a snippet from the list, but to get the voice ID I have to perform two clicks—one opens a menu with "Copy ID" and "Copy Link" options. The "Copy Link" URL takes me to a page that doesn’t display anything I can’t already see on the Text To Speech page.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Remove the "Copy Link" option and simply have a button to "Copy ID" at the top level for every voice.</em></span>

## Other Voice Tools

Clicking through other voice tools quickly, the cloning options make sense. Localize voice I don’t fully understand—and there's nothing explaining it on the page. Voice changer is similar, I can intuit what it means, but it's unclear.

<span style="font-size: 0.95em; color: #888;"><em>Idea: Add some text to explain the localizing and voice changer pages.</em></span>

## Library

I see there’s a separate `Library` section. I feel `Voices` could stand alone or be combined with `Text to Speech`. `Pronunciation` is definitely a good candidate for `Voice Tools.`

<span style="font-size: 0.95em; color: #888;"><em>Idea: The sidebar can be consolidated to `Voice`, `Line`, and `Platform`. `Voice` can contain everything it currently does plus `Pronunciation`. The `Voices` and `Text to Speech` pages can be consolidated (the primary value to users is finding a voice they like and generating snippets), and `Narration`, unless highly utilized, seems redundant and tries to compete with ElevenLabs.</em></span>

## Studio

I don't understand what differentiates the narration section from the Text-to-Speech page. Both have exports and let you view past generations. I believe Narrations allows you to save the audio file as well, but otherwise not materially different—it would be easy to add that to the `Text to Speech` page.

## Line
![Agent FTUX](/Public/agent-ftux.png)

I clicked around this panel.

First I tried Text-to-agent, and as far as I can tell, all it did was use what I typed in. It's unclear if I can edit this agent in Github. I have to promote it to production before being given the option.

![Text to Agent Prompting](/Public/text-to-agent-prompting.png)

<span style="font-size: 0.95em; color: #888;"><em>Idea: Users will want a warm start with Text-to-agent. It doesn't provide much value currently, but with tool-calling and code editing it could. Generally, tool-calling feels like a big opportunity.</em></span>

Then I tried "Connect your code".

I connected my Github and was asked to link a repo. I didn't have one, so backed out of that menu.

<span style="font-size: 0.95em; color: #888;"><em>Idea: For FTUX, maybe pre-seed new accounts with a starter agent. The current text-to-agent doesn't provide much value, so having users go through these steps is low ROI. Another idea is to nudge them toward a template. Instead of just saying "No Agents Found" when there are no agents, provide a CTA.</em></span>

Then, the templates available are of mixed value. The Basic Chat was fine but basic. The Form Filler was very good and thorough.

<span style="font-size: 0.95em; color: #888;"><em>Idea: I didn’t see any transfer logic or ability to update agent prompts.</em></span>

The repo itself is clear. Good README, clean code. It's very low level, which is great for productionizing but makes prototyping more of an investment.


